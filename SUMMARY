================================================================================
File: README.md
================================================================================
# 

## Introduction

This is a template repository that provides a foundation for GitHub Action-based agents. It includes a modular system for dynamic documentation generation and other reusable components that make it easier to build and maintain agent-driven workflows.

### Key Features

- Modular documentation system with Jinja2 templates
- Automatic project structure documentation
- Reusable GitHub Actions workflows
- Centralized configuration management
- Utility functions for common operations
- Clean, maintainable architecture optimized for AI agents
- Built-in test framework with pytest
- Automated workflow dependencies
- Git operations handled through utilities
## Repository Setup

### Required Repository Settings

1. **Workflow Permissions**
   - Go to Repository Settings → Actions → General → Workflow permissions
   - Enable "Read and write permissions"
   - Check "Allow GitHub Actions to create and approve pull requests"

2. **Branch Protection** (Optional but recommended)
   - Go to Repository Settings → Branches → Branch protection rules
   - Add rule for your main branch (e.g., `main` or `master`)
   - Enable:
     - "Require pull request reviews before merging"
     - "Require status checks to pass before merging"
   - Allow:
     - "Allow specific actors to bypass required pull requests"
     - Add "github-actions[bot]" to the bypass list

### Required Secrets and Variables

No additional secrets are required for basic functionality. The workflows use the default `GITHUB_TOKEN` which is automatically provided.

### Repository Setup Commands

If you're setting up using GitHub CLI, you can run these commands:
```bash
# Enable workflows
gh repo edit --enable-actions

# Set workflow permissions
gh api \
  --method PUT \
  -H "Accept: application/vnd.github+json" \
  "/repos/OWNER/REPO/actions/permissions/workflow" \
  -f default_workflow_permissions='write' \
  -F can_approve_pull_request_reviews=true

# Enable Issues (recommended for tracking)
gh repo edit --enable-issues
```

Replace `OWNER/REPO` with your repository details.

### Common Issues

1. **Workflow Permission Errors**
   - Error: "Resource not accessible by integration"
   - Solution: Ensure workflow permissions are set to "Read and write"

2. **Git Push Failures**
   - Error: "GitHub Actions is not permitted to create or approve pull requests"
   - Solution: Check "Allow GitHub Actions to create and approve pull requests"

3. **Workflow Trigger Issues**
   - Error: Workflows not triggering each other
   - Solution: Ensure `GITHUB_TOKEN` has sufficient permissions and "Read and write permissions" is enabled
## Usage

### Installation

This project is designed to be used as a template repository. To get started:

1. Click "Use this template" on GitHub
2. Clone your new repository
3. Install the development dependencies:
   ```bash
   pip install -e ".[test]"
   ```

### Dynamic README Generation

The README is automatically generated from templates in `docs/readme/`. The system works as follows:

1. Base template (`docs/readme/base.md.j2`) defines the overall structure
2. Individual sections are stored in `docs/readme/sections/` as separate templates
3. Configuration is centralized in `pyproject.toml`
4. GitHub Actions automatically rebuild the README when:
   - Templates are modified
   - Project structure changes
   - Configuration is updated

To manually trigger a README rebuild:
```bash
python -m readme_generator readme
```

### Project Structure Management

The repository includes automatic project structure documentation:

1. Structure is updated on file changes
2. Tree output is formatted as a template
3. README is automatically rebuilt to include the new structure

To manually update the structure:
```bash
python -m readme_generator structure
```

### Testing

The project uses pytest for testing. To run tests:

```bash
# Run all tests
pytest

# Run with coverage report
pytest --cov=readme_generator

# Run specific test file
pytest tests/test_tree_generator.py
```

Tests are automatically run:
- On every push to main
- When workflows are triggered
- Before README updates
- Before structure updates

### Development

This project follows a modular design principle to make it easier for AI agents to work with the codebase:

- Each component is self-contained and focused
- Configuration is centralized in `pyproject.toml`
- Utilities are designed to be reusable across workflows
- Git operations are handled through utility functions
- All features are tested using pytest

To add new README sections:
1. Create a new template in `docs/readme/sections/`
2. Include it in `docs/readme/base.md.j2`
3. Add any necessary configuration to `pyproject.toml`
4. Add tests for new functionality
## Development Guidelines

### Code Organization for LLM Interaction

When developing this project (or using it as a template), keep in mind these guidelines for effective collaboration with Large Language Models:

1. **Separation of Concerns**
   - Each package should have a single, clear responsibility
   - New features should be separate packages when appropriate
   - Avoid coupling between packages
   - Use consistent patterns across packages, but implement independently
   - Cross-cutting concerns should use shared conventions

2. **File Length and Modularity**
   - Keep files short and focused on a single responsibility
   - If you find yourself using comments like "... rest remains the same" or "... etc", the file is too long
   - Files should be completely replaceable in a single LLM interaction
   - Long files should be split into logical components

3. **Dependencies**
   - All dependencies managed in `pyproject.toml`
   - Optional dependencies grouped by feature:
     ```toml
     [project.optional-dependencies]
     test = ["pytest", ...]
     site = ["markdown2", ...]
     all = ["pytest", "markdown2", ...]  # Everything
     ```
   - Use appropriate groups during development:
     ```bash
     pip install -e ".[test]"  # Just testing
     pip install -e ".[all]"   # Everything
     ```

4. **Testing Standards**
   - Every new feature needs tests
   - Tests should be clear and focused
   - Use pytest fixtures for common setups
   - All workflows depend on tests passing
   - Test files should follow same modularity principles

5. **Why This Matters**
   - LLMs work best with clear, focused contexts
   - Complete file contents are better than partial updates with ellipsis
   - Tests provide clear examples of intended behavior
   - Shorter files make it easier for LLMs to:
     - Understand the complete context
     - Suggest accurate modifications
     - Maintain consistency
     - Avoid potential errors from incomplete information

6. **Real World Example**
   Our own organization follows these principles:
   ```
   src/
   ├── readme_generator/  # Core README generation
   │   ├── generators/
   │   └── utils.py
   └── site_generator/    # Demo site generation
       ├── generator.py
       └── __main__.py
   ```

7. **Best Practices**
   - Aim for files under 200 lines
   - Each file should have a single, clear purpose
   - Use directory structure to organize related components
   - Prefer many small files over few large files
   - Consider splitting when files require partial updates
   - Write tests alongside new features
   - Run tests locally before pushing
# LLM-Focused Summary System

## Overview
The project includes an automated summary generation system designed to help LLMs efficiently work with the codebase. This system generates both local directory summaries and project-wide summaries to provide focused, relevant context for different tasks.

## Types of Summaries

### Directory Summaries
Each directory in the project contains a `SUMMARY` file that concatenates all text files in that directory. This provides focused, local context when working on directory-specific tasks.

### Project-Wide Summaries
Special project-wide summaries are maintained in the `SUMMARIES/` directory on the `summaries` branch:

- `READMEs.md`: Concatenation of all README files in the project
- `README_SUBs.md`: Same as above but excluding the root README
- `PYTHON.md`: Structured view of all Python code including:
  - Function and class signatures
  - Type hints
  - Docstrings
  - Clear indication of class membership

## Accessing Summaries

### Directory Summaries
These are available on any branch in their respective directories:
```bash
# Example: View summary for the readme_generator package
cat src/readme_generator/SUMMARY
```

### Project-Wide Summaries
These live exclusively on the `summaries` branch:
```bash
# Switch to summaries branch
git checkout summaries

# View available summaries
ls SUMMARIES/
```

## Using Summaries Effectively

### For Local Development
Directory summaries are useful when:
- Getting up to speed on a specific package
- Understanding local code context
- Planning modifications to a package

### For Project-Wide Understanding
The `SUMMARIES/` directory helps with:
- Understanding overall project structure
- Finding relevant code across packages
- Reviewing API signatures and documentation
- Planning cross-package changes

### For LLM Interactions
- Point LLMs to specific summaries based on the task
- Use directory summaries for focused work
- Use project-wide summaries for architectural decisions
- Combine different summaries as needed for context

## Implementation Notes
- Summaries are automatically updated on every push to `main`
- The `summaries` branch is workflow-owned and force-pushed on updates
- Summary generation is configured in `pyproject.toml` under `[tool.summary]`
- Don't modify summaries directly - they're automatically generated
## GitHub Pages

### Requirements

1. **Public Repository**
   - GitHub Pages is available out-of-the-box for public repositories
   - For private repositories, a GitHub Enterprise plan is required
   - If you plan to make your repository public later, you can still set up and test the site generation locally

2. **Repository Settings**
   - Once your repository is public (or on an Enterprise plan):
     - Go to Repository Settings → Pages
     - Under "Build and deployment":
       - Set Source to "GitHub Actions"

### Installation

```bash
# Install with site generation dependencies
pip install -e ".[all]"
```

### Local Development

The site generator can be used locally regardless of repository visibility:

```bash
# Generate site locally
python -m site_generator build

# Site will be generated in _site/ directory (git-ignored)
# View the generated site by opening _site/index.html in your browser
```

### GitHub Actions Integration

When requirements are met (public repository or Enterprise plan), the site automatically rebuilds and deploys when:
- The README is updated through the `build-readme` workflow
- The deployment workflow is modified
- The workflow is manually triggered

### File Structure

```
your-repo/
├── _site/           # Generated directory (git-ignored)
│   └── index.html   # Generated site
├── docs/
│   └── site/       
│       └── template.html  # Site template
└── src/
    └── site_generator/   # Generator package
```

### Customization

The site template is located in `docs/site/template.html` and can be customized with:
- Custom CSS styles
- Additional JavaScript
- Modified layout and structure
- Custom header/footer content

### Command Line Usage

```bash
# Generate site with default settings
python -m site_generator build

# Specify custom output directory
python -m site_generator build --output_dir="custom_dir"
```

### Testing

The site generation can be tested locally even if GitHub Pages deployment isn't available:
```bash
# Run the test suite
pytest tests/test_site_generator.py
```
## Project Structure

The repository is organized as follows:

```
ai-gha
├── .github
│   └── workflows
│       ├── README.md
│       ├── build-readme.yml
│       ├── deploy-gh-pages.yml
│       ├── generate-summaries.yml
│       ├── test.yml
│       └── update-structure.yml
├── .gitignore
├── LICENSE
├── README.md
├── docs
│   ├── README.md
│   ├── readme
│   │   ├── README.md
│   │   ├── base.md.j2
│   │   └── sections
│   │       ├── development.md.j2
│   │       ├── introduction.md.j2
│   │       ├── prerequisites.md.j2
│   │       ├── site.md.j2
│   │       ├── structure.md.j2
│   │       ├── summaries.md.j2
│   │       ├── todo.md.j2
│   │       └── usage.md.j2
│   └── site
│       ├── README.md
│       └── template.html
├── pyproject.toml
├── src
│   ├── README.md
│   ├── readme_generator
│   │   ├── README.md
│   │   ├── __init__.py
│   │   ├── __main__.py
│   │   ├── generators
│   │   │   ├── README.md
│   │   │   ├── __init__.py
│   │   │   ├── readme_generator.py
│   │   │   ├── structure_generator.py
│   │   │   └── tree_generator.py
│   │   └── utils.py
│   ├── site_generator
│   │   ├── README.md
│   │   ├── __init__.py
│   │   ├── __main__.py
│   │   └── generator.py
│   └── summary_generator
│       ├── README.md
│       ├── __init__.py
│       ├── __main__.py
│       ├── generator.py
│       ├── signature_extractor.py
│       └── special_summaries.py
└── tests
    ├── conftest.py
    ├── test_generators.py
    ├── test_site_generator.py
    ├── test_summary_generator.py
    └── test_tree_generator.py

```

### Key Components

- `.github/workflows/`: GitHub Actions workflow definitions
  - `build-readme.yml`: Automatically rebuilds README when content changes
  - `update-structure.yml`: Updates project structure documentation

- `docs/readme/`: README template files
  - `base.md.j2`: Main template file
  - `sections/`: Individual section templates

- `src/readme_generator/`: Core Python package
  - `generators/`: Generation components
    - `tree_generator.py`: Tree generation utilities
    - `readme_generator.py`: README generation logic
    - `structure_generator.py`: Structure documentation
  - `utils.py`: Shared utility functions
  - `__main__.py`: CLI entry point

- `pyproject.toml`: Project configuration and dependencies
## TODO

### Documentation Improvements
- [ ] Add automatic table of contents generation
- [ ] Add module summary with function signatures
- [ ] Expand documentation with more examples
- [ ] Add API integration instructions

### Feature Additions
- [ ] Add more utility functions for common agent operations
- [ ] Create workflow templates for common agent tasks
- [ ] Add more reusable components
- [ ] Add GitHub Pages integration for project documentation

### Testing Enhancements
- [ ] Add more test cases for edge cases
- [ ] Add integration tests for workflows
- [ ] Improve test coverage



================================================================================
File: docs/README.md
================================================================================
# Documentation

Project documentation and templates.

## Conventions

- Use Jinja2 for templates
- Keep documentation focused and modular
- Put README templates in `readme/`
- Follow markdown best practices
- Keep sections independent

## Directory Structure

- `readme/`: README generation templates
  - Templates use `.md.j2` extension
  - Sections are modular and focused
  - Configuration in `pyproject.toml`

## Adding Documentation

1. Choose appropriate subdirectory
2. Follow existing patterns and conventions
3. Update structure documentation if needed



================================================================================
File: docs/readme/README.md
================================================================================
# README Templates

Templates and sections for dynamic README generation.

## Conventions

- Use Jinja2 templates with `.md.j2` extension
- Base template goes in this directory
- Individual sections go in `sections/`
- Section templates should be focused and modular
- Variables come from `pyproject.toml`
- Follow markdown best practices

## Directory Structure

- `base.md.j2`: Main README template
- `sections/`: Individual section templates
  - Each section should focus on one aspect
  - Name templates descriptively: `<topic>.md.j2`
  - Keep sections modular and independent

## Adding New Sections

1. Create new section in `sections/`
2. Add to `base.md.j2` using include
3. Add any needed variables to `pyproject.toml`



================================================================================
File: docs/readme/base.md.j2
================================================================================
# {{ title }}

{# Get all section templates and include them with proper path #}
{% for template in get_section_templates() %}
{% include "sections/" ~ template %}

{% endfor %}



================================================================================
File: docs/readme/sections/development.md.j2
================================================================================
## Development Guidelines

### Code Organization for LLM Interaction

When developing this project (or using it as a template), keep in mind these guidelines for effective collaboration with Large Language Models:

1. **Separation of Concerns**
   - Each package should have a single, clear responsibility
   - New features should be separate packages when appropriate
   - Avoid coupling between packages
   - Use consistent patterns across packages, but implement independently
   - Cross-cutting concerns should use shared conventions

2. **File Length and Modularity**
   - Keep files short and focused on a single responsibility
   - If you find yourself using comments like "... rest remains the same" or "... etc", the file is too long
   - Files should be completely replaceable in a single LLM interaction
   - Long files should be split into logical components

3. **Dependencies**
   - All dependencies managed in `pyproject.toml`
   - Optional dependencies grouped by feature:
     ```toml
     [project.optional-dependencies]
     test = ["pytest", ...]
     site = ["markdown2", ...]
     all = ["pytest", "markdown2", ...]  # Everything
     ```
   - Use appropriate groups during development:
     ```bash
     pip install -e ".[test]"  # Just testing
     pip install -e ".[all]"   # Everything
     ```

4. **Testing Standards**
   - Every new feature needs tests
   - Tests should be clear and focused
   - Use pytest fixtures for common setups
   - All workflows depend on tests passing
   - Test files should follow same modularity principles

5. **Why This Matters**
   - LLMs work best with clear, focused contexts
   - Complete file contents are better than partial updates with ellipsis
   - Tests provide clear examples of intended behavior
   - Shorter files make it easier for LLMs to:
     - Understand the complete context
     - Suggest accurate modifications
     - Maintain consistency
     - Avoid potential errors from incomplete information

6. **Real World Example**
   Our own organization follows these principles:
   ```
   src/
   ├── readme_generator/  # Core README generation
   │   ├── generators/
   │   └── utils.py
   └── site_generator/    # Demo site generation
       ├── generator.py
       └── __main__.py
   ```

7. **Best Practices**
   - Aim for files under 200 lines
   - Each file should have a single, clear purpose
   - Use directory structure to organize related components
   - Prefer many small files over few large files
   - Consider splitting when files require partial updates
   - Write tests alongside new features
   - Run tests locally before pushing



================================================================================
File: docs/readme/sections/introduction.md.j2
================================================================================
## Introduction

This is a template repository that provides a foundation for GitHub Action-based agents. It includes a modular system for dynamic documentation generation and other reusable components that make it easier to build and maintain agent-driven workflows.

### Key Features

- Modular documentation system with Jinja2 templates
- Automatic project structure documentation
- Reusable GitHub Actions workflows
- Centralized configuration management
- Utility functions for common operations
- Clean, maintainable architecture optimized for AI agents
- Built-in test framework with pytest
- Automated workflow dependencies
- Git operations handled through utilities



================================================================================
File: docs/readme/sections/prerequisites.md.j2
================================================================================
## Repository Setup

### Required Repository Settings

1. **Workflow Permissions**
   - Go to Repository Settings → Actions → General → Workflow permissions
   - Enable "Read and write permissions"
   - Check "Allow GitHub Actions to create and approve pull requests"

2. **Branch Protection** (Optional but recommended)
   - Go to Repository Settings → Branches → Branch protection rules
   - Add rule for your main branch (e.g., `main` or `master`)
   - Enable:
     - "Require pull request reviews before merging"
     - "Require status checks to pass before merging"
   - Allow:
     - "Allow specific actors to bypass required pull requests"
     - Add "github-actions[bot]" to the bypass list

### Required Secrets and Variables

No additional secrets are required for basic functionality. The workflows use the default `GITHUB_TOKEN` which is automatically provided.

### Repository Setup Commands

If you're setting up using GitHub CLI, you can run these commands:
```bash
# Enable workflows
gh repo edit --enable-actions

# Set workflow permissions
gh api \
  --method PUT \
  -H "Accept: application/vnd.github+json" \
  "/repos/OWNER/REPO/actions/permissions/workflow" \
  -f default_workflow_permissions='write' \
  -F can_approve_pull_request_reviews=true

# Enable Issues (recommended for tracking)
gh repo edit --enable-issues
```

Replace `OWNER/REPO` with your repository details.

### Common Issues

1. **Workflow Permission Errors**
   - Error: "Resource not accessible by integration"
   - Solution: Ensure workflow permissions are set to "Read and write"

2. **Git Push Failures**
   - Error: "GitHub Actions is not permitted to create or approve pull requests"
   - Solution: Check "Allow GitHub Actions to create and approve pull requests"

3. **Workflow Trigger Issues**
   - Error: Workflows not triggering each other
   - Solution: Ensure `GITHUB_TOKEN` has sufficient permissions and "Read and write permissions" is enabled



================================================================================
File: docs/readme/sections/site.md.j2
================================================================================
## GitHub Pages

### Requirements

1. **Public Repository**
   - GitHub Pages is available out-of-the-box for public repositories
   - For private repositories, a GitHub Enterprise plan is required
   - If you plan to make your repository public later, you can still set up and test the site generation locally

2. **Repository Settings**
   - Once your repository is public (or on an Enterprise plan):
     - Go to Repository Settings → Pages
     - Under "Build and deployment":
       - Set Source to "GitHub Actions"

### Installation

```bash
# Install with site generation dependencies
pip install -e ".[all]"
```

### Local Development

The site generator can be used locally regardless of repository visibility:

```bash
# Generate site locally
python -m site_generator build

# Site will be generated in _site/ directory (git-ignored)
# View the generated site by opening _site/index.html in your browser
```

### GitHub Actions Integration

When requirements are met (public repository or Enterprise plan), the site automatically rebuilds and deploys when:
- The README is updated through the `build-readme` workflow
- The deployment workflow is modified
- The workflow is manually triggered

### File Structure

```
your-repo/
├── _site/           # Generated directory (git-ignored)
│   └── index.html   # Generated site
├── docs/
│   └── site/       
│       └── template.html  # Site template
└── src/
    └── site_generator/   # Generator package
```

### Customization

The site template is located in `docs/site/template.html` and can be customized with:
- Custom CSS styles
- Additional JavaScript
- Modified layout and structure
- Custom header/footer content

### Command Line Usage

```bash
# Generate site with default settings
python -m site_generator build

# Specify custom output directory
python -m site_generator build --output_dir="custom_dir"
```

### Testing

The site generation can be tested locally even if GitHub Pages deployment isn't available:
```bash
# Run the test suite
pytest tests/test_site_generator.py
```



================================================================================
File: docs/readme/sections/structure.md.j2
================================================================================
## Project Structure

The repository is organized as follows:

```
ai-gha
├── .github
│   └── workflows
│       ├── README.md
│       ├── build-readme.yml
│       ├── deploy-gh-pages.yml
│       ├── generate-summaries.yml
│       ├── test.yml
│       └── update-structure.yml
├── .gitignore
├── LICENSE
├── README.md
├── docs
│   ├── README.md
│   ├── readme
│   │   ├── README.md
│   │   ├── base.md.j2
│   │   └── sections
│   │       ├── development.md.j2
│   │       ├── introduction.md.j2
│   │       ├── prerequisites.md.j2
│   │       ├── site.md.j2
│   │       ├── structure.md.j2
│   │       ├── summaries.md.j2
│   │       ├── todo.md.j2
│   │       └── usage.md.j2
│   └── site
│       ├── README.md
│       └── template.html
├── pyproject.toml
├── src
│   ├── README.md
│   ├── readme_generator
│   │   ├── README.md
│   │   ├── __init__.py
│   │   ├── __main__.py
│   │   ├── generators
│   │   │   ├── README.md
│   │   │   ├── __init__.py
│   │   │   ├── readme_generator.py
│   │   │   ├── structure_generator.py
│   │   │   └── tree_generator.py
│   │   └── utils.py
│   ├── site_generator
│   │   ├── README.md
│   │   ├── __init__.py
│   │   ├── __main__.py
│   │   └── generator.py
│   └── summary_generator
│       ├── README.md
│       ├── __init__.py
│       ├── __main__.py
│       ├── generator.py
│       ├── signature_extractor.py
│       └── special_summaries.py
└── tests
    ├── conftest.py
    ├── test_generators.py
    ├── test_site_generator.py
    ├── test_summary_generator.py
    └── test_tree_generator.py

```

### Key Components

- `.github/workflows/`: GitHub Actions workflow definitions
  - `build-readme.yml`: Automatically rebuilds README when content changes
  - `update-structure.yml`: Updates project structure documentation

- `docs/readme/`: README template files
  - `base.md.j2`: Main template file
  - `sections/`: Individual section templates

- `src/readme_generator/`: Core Python package
  - `generators/`: Generation components
    - `tree_generator.py`: Tree generation utilities
    - `readme_generator.py`: README generation logic
    - `structure_generator.py`: Structure documentation
  - `utils.py`: Shared utility functions
  - `__main__.py`: CLI entry point

- `pyproject.toml`: Project configuration and dependencies



================================================================================
File: docs/readme/sections/summaries.md.j2
================================================================================
# LLM-Focused Summary System

## Overview
The project includes an automated summary generation system designed to help LLMs efficiently work with the codebase. This system generates both local directory summaries and project-wide summaries to provide focused, relevant context for different tasks.

## Types of Summaries

### Directory Summaries
Each directory in the project contains a `SUMMARY` file that concatenates all text files in that directory. This provides focused, local context when working on directory-specific tasks.

### Project-Wide Summaries
Special project-wide summaries are maintained in the `SUMMARIES/` directory on the `summaries` branch:

- `READMEs.md`: Concatenation of all README files in the project
- `README_SUBs.md`: Same as above but excluding the root README
- `PYTHON.md`: Structured view of all Python code including:
  - Function and class signatures
  - Type hints
  - Docstrings
  - Clear indication of class membership

## Accessing Summaries

### Directory Summaries
These are available on any branch in their respective directories:
```bash
# Example: View summary for the readme_generator package
cat src/readme_generator/SUMMARY
```

### Project-Wide Summaries
These live exclusively on the `summaries` branch:
```bash
# Switch to summaries branch
git checkout summaries

# View available summaries
ls SUMMARIES/
```

## Using Summaries Effectively

### For Local Development
Directory summaries are useful when:
- Getting up to speed on a specific package
- Understanding local code context
- Planning modifications to a package

### For Project-Wide Understanding
The `SUMMARIES/` directory helps with:
- Understanding overall project structure
- Finding relevant code across packages
- Reviewing API signatures and documentation
- Planning cross-package changes

### For LLM Interactions
- Point LLMs to specific summaries based on the task
- Use directory summaries for focused work
- Use project-wide summaries for architectural decisions
- Combine different summaries as needed for context

## Implementation Notes
- Summaries are automatically updated on every push to `main`
- The `summaries` branch is workflow-owned and force-pushed on updates
- Summary generation is configured in `pyproject.toml` under `[tool.summary]`
- Don't modify summaries directly - they're automatically generated



================================================================================
File: docs/readme/sections/todo.md.j2
================================================================================
## TODO

### Documentation Improvements
- [ ] Add automatic table of contents generation
- [ ] Add module summary with function signatures
- [ ] Expand documentation with more examples
- [ ] Add API integration instructions

### Feature Additions
- [ ] Add more utility functions for common agent operations
- [ ] Create workflow templates for common agent tasks
- [ ] Add more reusable components
- [ ] Add GitHub Pages integration for project documentation

### Testing Enhancements
- [ ] Add more test cases for edge cases
- [ ] Add integration tests for workflows
- [ ] Improve test coverage



================================================================================
File: docs/readme/sections/usage.md.j2
================================================================================
## Usage

### Installation

This project is designed to be used as a template repository. To get started:

1. Click "Use this template" on GitHub
2. Clone your new repository
3. Install the development dependencies:
   ```bash
   pip install -e ".[test]"
   ```

### Dynamic README Generation

The README is automatically generated from templates in `docs/readme/`. The system works as follows:

1. Base template (`docs/readme/base.md.j2`) defines the overall structure
2. Individual sections are stored in `docs/readme/sections/` as separate templates
3. Configuration is centralized in `pyproject.toml`
4. GitHub Actions automatically rebuild the README when:
   - Templates are modified
   - Project structure changes
   - Configuration is updated

To manually trigger a README rebuild:
```bash
python -m readme_generator readme
```

### Project Structure Management

The repository includes automatic project structure documentation:

1. Structure is updated on file changes
2. Tree output is formatted as a template
3. README is automatically rebuilt to include the new structure

To manually update the structure:
```bash
python -m readme_generator structure
```

### Testing

The project uses pytest for testing. To run tests:

```bash
# Run all tests
pytest

# Run with coverage report
pytest --cov=readme_generator

# Run specific test file
pytest tests/test_tree_generator.py
```

Tests are automatically run:
- On every push to main
- When workflows are triggered
- Before README updates
- Before structure updates

### Development

This project follows a modular design principle to make it easier for AI agents to work with the codebase:

- Each component is self-contained and focused
- Configuration is centralized in `pyproject.toml`
- Utilities are designed to be reusable across workflows
- Git operations are handled through utility functions
- All features are tested using pytest

To add new README sections:
1. Create a new template in `docs/readme/sections/`
2. Include it in `docs/readme/base.md.j2`
3. Add any necessary configuration to `pyproject.toml`
4. Add tests for new functionality



================================================================================
File: docs/site/README.md
================================================================================
# Site Templates

This directory contains templates and assets for the project's GitHub Pages site.

## Overview
The site generator creates a simple static site that displays the project's README with GitHub-style formatting.

## Files
- `template.html`: Base template for the generated site
  - Uses GitHub markdown styling
  - Supports dark/light mode
  - Responsive design
  - Code syntax highlighting

## Customization
To customize the site appearance:
1. Modify `template.html`
2. Add custom CSS in the template
3. Add custom JavaScript if needed

Note: The site generator is intentionally minimal, serving only as a demo of GitHub Actions integration.



================================================================================
File: docs/site/template.html
================================================================================
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>readme-generator - GitHub Action-based Documentation</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/github-markdown-css/5.5.0/github-markdown.min.css">
    <style>
        /* Light mode styles */
        :root {
            --color-bg: #ffffff;
            --color-text: #24292f;
            --color-link: #0969da;
            --color-border: #d0d7de;
        }
        
        /* Dark mode styles */
        @media (prefers-color-scheme: dark) {
            :root {
                --color-bg: #0d1117;
                --color-text: #c9d1d9;
                --color-link: #58a6ff;
                --color-border: #30363d;
            }
            .markdown-body {
                color-scheme: dark;
                --color-prettylights-syntax-comment: #8b949e;
                --color-prettylights-syntax-constant: #79c0ff;
                --color-prettylights-syntax-entity: #d2a8ff;
                --color-prettylights-syntax-storage-modifier-import: #c9d1d9;
                --color-prettylights-syntax-keyword: #ff7b72;
                --color-prettylights-syntax-string: #a5d6ff;
                --color-prettylights-syntax-variable: #ffa657;
                --color-prettylights-syntax-brackethighlighter-unmatched: #f85149;
                --color-prettylights-syntax-invalid-illegal-text: #f0f6fc;
                --color-prettylights-syntax-invalid-illegal-bg: #8e1519;
                --color-prettylights-syntax-carriage-return-text: #f0f6fc;
                --color-prettylights-syntax-carriage-return-bg: #b62324;
                --color-prettylights-syntax-string-regexp: #7ee787;
                --color-prettylights-syntax-markup-list: #f2cc60;
                --color-prettylights-syntax-markup-heading: #1f6feb;
                --color-prettylights-syntax-markup-italic: #c9d1d9;
                --color-prettylights-syntax-markup-bold: #c9d1d9;
                --color-prettylights-syntax-markup-deleted-text: #ffdcd7;
                --color-prettylights-syntax-markup-deleted-bg: #67060c;
                --color-prettylights-syntax-markup-inserted-text: #aff5b4;
                --color-prettylights-syntax-markup-inserted-bg: #033a16;
                --color-prettylights-syntax-markup-changed-text: #ffdfb6;
                --color-prettylights-syntax-markup-changed-bg: #5a1e02;
                --color-prettylights-syntax-markup-ignored-text: #c9d1d9;
                --color-prettylights-syntax-markup-ignored-bg: #1158c7;
                --color-prettylights-syntax-meta-diff-range: #d2a8ff;
                --color-prettylights-syntax-brackethighlighter-angle: #8b949e;
                --color-prettylights-syntax-sublimelinter-gutter-mark: #484f58;
                --color-prettylights-syntax-constant-other-reference-link: #a5d6ff;
            }
        }

        body {
            margin: 0;
            padding: 0;
            background-color: var(--color-bg);
            color: var(--color-text);
        }

        .container {
            max-width: 850px;
            margin: 0 auto;
            padding: 2rem 1rem;
        }

        .markdown-body {
            background-color: transparent !important;
        }

        @media (max-width: 767px) {
            .markdown-body {
                padding: 15px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <main class="markdown-body">
            {{content}}
        </main>
    </div>
</body>
</html>



================================================================================
File: pyproject.toml
================================================================================
[project]
name = "readme-generator"
version = "0.1.0"
description = "Template repository for GitHub Action-based agents with dynamic documentation"
requires-python = ">=3.11"
dependencies = [
    "Jinja2>=3.1.2",
    "tomli>=2.0.1",
    "loguru>=0.7.0",
    "fire>=0.5.0",
    "tree-format>=0.1.2",
]

[project.optional-dependencies]
test = [
    "pytest>=7.0",
    "pytest-cov>=4.0",
]
site = [
    "markdown2>=2.4.0",
]
summary = [
    "loguru>=0.7.0",
    "fire>=0.5.0",
]
# Meta-dependency that includes everything
all = [
    "pytest>=7.0",
    "pytest-cov>=4.0",
    "markdown2>=2.4.0",
]

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py"]
addopts = "-v --cov=readme_generator --cov=summary_generator"

[tool.readme.tree]
ignore_patterns = [
    "__pycache__",
    "*.pyc",
    ".git",
    ".venv",
    ".pytest_cache",
    ".vscode",
    ".idea",
    "*.egg-info",
]

[tool.summary]
ignore_patterns = [
    "__pycache__",
    "*.pyc",
    ".git",
    ".github/workflows",  # Explicitly exclude workflows directory
    ".venv",
    ".pytest_cache",
    ".vscode",
    ".idea",
    "*.egg-info",
    "SUMMARY",
    ".coverage",
]



================================================================================
File: src/README.md
================================================================================
# Source Packages
This directory contains the core packages for the project. The codebase follows strict separation of concerns and modular design principles to maintain clean, maintainable, and LLM-friendly code.

## Core Principles
### Separation of Concerns
- Each package has a single, well-defined responsibility
- Packages are independent and self-contained
- Cross-cutting concerns (logging, CLI) use consistent patterns
- New features should be built as separate packages when appropriate
- Shared utilities only for truly common functionality

### Package Organization
- Each package is self-contained and focused
- READMEs document package-specific details
- Tests live in the root `tests/` directory
- Common patterns implemented independently per package

## Development Conventions
### Code Style
- Keep files short and focused (see development guidelines in main README)
- Use relative imports within packages
- Follow consistent naming patterns
- Avoid filenames that conflict with GitHub conventions
- Type hints should use:
  - Built-in generics over typing module (PEP 585)
    ```python
    # Good
    def process_items(items: list[str]) -> dict[str, int]:
        pass
        
    # Avoid
    from typing import List, Dict
    def process_items(items: List[str]) -> Dict[str, int]:
        pass
    ```
  - Union operator (`|`) over Optional (PEP 604)
    ```python
    # Good
    def get_value(key: str) -> str | None:
        pass
        
    # Avoid
    from typing import Optional
    def get_value(key: str) -> Optional[str]:
        pass
    ```
  - Enable flake8-pep585 in your editor to automatically flag outdated syntax

### Dependencies
- All dependencies declared in root `pyproject.toml`
- Dependencies organized into optional feature groups
- Use `[all]` for complete development environment
- Example usage:
  ```bash
  # Install specific features
  pip install -e ".[test]"     # Just testing deps
  pip install -e ".[site]"     # Just site generation deps
  
  # Install everything
  pip install -e ".[all]"      # All optional dependencies
  ```

### Logging & CLI
- Use `loguru` for all logging
- Use `fire` for CLI interfaces
- Consistent command patterns across packages

### Testing
- Write tests first (TDD approach)
- Use `pytest` fixtures for common setups
- Keep tests focused and well-documented
- Run tests locally before pushing
- All workflows depend on tests passing

### Git Operations
- Use `utils.commit_and_push` for all git operations
  - Set `force=True` for workflow-owned branches (e.g., generated content)
  - Use default behavior for normal collaborative branches
- Follow consistent commit message patterns
- Let workflows handle automated commits

## Current Packages
- `readme_generator/`: Dynamic README generation and maintenance
- `site_generator/`: Static site generation for demo purposes
- `summary_generator/`: Project content summary generation for LLM context. Outputs to `summaries` branch.



================================================================================
File: src/readme_generator/README.md
================================================================================
# README Generator Package

Core package for dynamic README generation and maintenance.

## Components

### Generators
- `readme_generator.py`: Core README generation logic
- `structure_generator.py`: Project structure documentation
- `tree_generator.py`: Directory tree visualization

### Utilities
- `utils.py`: Shared utility functions
- `__main__.py`: CLI entrypoint

## Features
- Template-based README generation
- Automatic structure documentation
- Directory tree visualization
- Git integration for automated updates

## Usage

```bash
# Generate README
python -m readme_generator readme

# Update structure documentation
python -m readme_generator structure

# Generate directory tree
python -m readme_generator tree
```

## Testing

Package-specific tests are in `tests/`:
- `test_generators.py`
- `test_tree_generator.py`

Run tests with:
```bash
pytest tests/
```



================================================================================
File: src/readme_generator/__init__.py
================================================================================




================================================================================
File: src/readme_generator/__main__.py
================================================================================
from loguru import logger
import fire
from .generators import generate_readme, update_structure, generate_tree

class ReadmeGenerator:
    """CLI for README generation and maintenance"""
    
    def readme(self) -> None:
        """Generate and update the README.md file"""
        generate_readme()
    
    def structure(self) -> None:
        """Update the project structure documentation"""
        update_structure()
    
    def tree(self, path: str = ".") -> None:
        """Print the project structure tree"""
        print(generate_tree(path))

if __name__ == "__main__":
    fire.Fire(ReadmeGenerator)



================================================================================
File: src/readme_generator/generators/README.md
================================================================================
# Generators

Component generators for various parts of the project.

## Conventions

- Each generator should be in its own file
- Keep files focused on a single generation task
- Follow naming pattern: `*_generator.py`
- Expose public functions through `__init__.py`
- All git operations should use `utils.commit_and_push`
- Each generator should be independently usable

## Key Components

- `readme_generator.py`: Main README generation
- `structure_generator.py`: Project structure documentation
- `tree_generator.py`: Directory tree generation utilities

## Adding New Generators

1. Create a new `*_generator.py` file
2. Implement the generator function
3. Export it in `__init__.py`
4. Update CLI if needed



================================================================================
File: src/readme_generator/generators/__init__.py
================================================================================
from .readme_generator import generate_readme
from .structure_generator import update_structure
from .tree_generator import generate_tree

__all__ = ['generate_readme', 'update_structure', 'generate_tree']



================================================================================
File: src/readme_generator/generators/readme_generator.py
================================================================================
from pathlib import Path
from typing import List
from loguru import logger
from jinja2 import Environment, FileSystemLoader
from ..utils import load_config, get_project_root, commit_and_push

def get_section_templates(template_dir: Path) -> List[str]:
    """Get all section templates in proper order.
    
    Args:
        template_dir: Path to template directory containing sections/
        
    Returns:
        List of template names in desired order
    """
    # Define section order
    section_order = {
        "introduction.md.j2": 0,
        "prerequisites.md.j2": 1,
        "usage.md.j2": 2,
        "development.md.j2": 3,
        "summaries.md.j2": 4,
        "site.md.j2": 5,
        "structure.md.j2": 6,
        "todo.md.j2": 999  # Always last if present
    }
    
    sections_dir = template_dir / "sections"
    templates = []
    
    # Collect all template files
    for file in sections_dir.glob("*.md.j2"):
        # Skip todo if it doesn't exist (it's optional)
        if file.name == "todo.md.j2" and not file.exists():
            continue
        templates.append(file.name)
    
    # Sort by explicit order, then alphabetically for any new sections
    return sorted(
        templates,
        key=lambda x: section_order.get(x, 500)
    )

def generate_readme() -> None:
    """Generate README from templates and commit changes"""
    project_root = get_project_root()
    logger.debug(f"Project root identified as: {project_root}")
    
    logger.info("Loading configurations")
    project_config = load_config("pyproject.toml")
    
    logger.info("Setting up Jinja2 environment")
    template_dir = project_root / 'docs/readme'
    logger.debug(f"Template directory: {template_dir}")
    
    env = Environment(
        loader=FileSystemLoader(template_dir),
        trim_blocks=True,
        lstrip_blocks=True
    )
    
    # Add template utility functions
    env.globals['get_section_templates'] = lambda: get_section_templates(template_dir)
    
    template = env.get_template('base.md.j2')
    
    variables = {
        'project': project_config['project'],
        'readme': project_config['tool']['readme'],
    }
    
    logger.info("Rendering README template")
    output = template.render(**variables)
    
    readme_path = project_root / 'README.md'
    logger.debug(f"Writing README to: {readme_path}")
    readme_path.write_text(output)
    
    logger.info("Committing changes")
    commit_and_push('README.md')



================================================================================
File: src/readme_generator/generators/structure_generator.py
================================================================================
from pathlib import Path
from loguru import logger
from ..utils import get_project_root, commit_and_push
from .tree_generator import generate_tree

def update_structure() -> None:
    """Update the structure template and commit changes"""
    project_root = get_project_root()
    template_path = "docs/readme/sections/structure.md.j2"
    full_template_path = project_root / template_path
    
    tree = generate_tree(str(project_root))
    template_content = f"""## Project Structure

The repository is organized as follows:

```
{tree}
```

### Key Components

- `.github/workflows/`: GitHub Actions workflow definitions
  - `build-readme.yml`: Automatically rebuilds README when content changes
  - `update-structure.yml`: Updates project structure documentation

- `docs/readme/`: README template files
  - `base.md.j2`: Main template file
  - `sections/`: Individual section templates

- `src/readme_generator/`: Core Python package
  - `generators/`: Generation components
    - `tree_generator.py`: Tree generation utilities
    - `readme_generator.py`: README generation logic
    - `structure_generator.py`: Structure documentation
  - `utils.py`: Shared utility functions
  - `__main__.py`: CLI entry point

- `pyproject.toml`: Project configuration and dependencies
"""
    
    full_template_path.parent.mkdir(parents=True, exist_ok=True)
    with open(full_template_path, 'w') as f:
        f.write(template_content)
    
    commit_and_push(template_path)



================================================================================
File: src/readme_generator/generators/tree_generator.py
================================================================================
from pathlib import Path
from typing import Optional, Tuple
from loguru import logger
from tree_format import format_tree
from ..utils import load_config
import fnmatch

def should_include_path(path: Path, config: dict) -> bool:
    """
    Determine if a path should be included in the tree.
    Only excludes paths that exactly match ignore patterns.
    """
    path_str = str(path)
    logger.debug(f"Checking path: {path_str}")
    
    # Check against ignore patterns
    ignore_patterns = set(config["tool"]["readme"]["tree"]["ignore_patterns"])
    
    # Split path into parts and check each part against patterns
    path_parts = path_str.split('/')
    for pattern in ignore_patterns:
        for part in path_parts:
            if fnmatch.fnmatch(part, pattern):
                logger.debug(f"Path {path_str} matched ignore pattern {pattern}")
                return False
    
    logger.debug(f"Path {path_str} included")
    return True

def node_to_tree(path: Path, config: dict) -> Optional[Tuple[str, list]]:
    """Convert a path to a tree node format"""
    logger.debug(f"Processing node: {path}")
    
    if not should_include_path(path, config):
        logger.debug(f"Excluding node: {path}")
        return None
    
    if path.is_file():
        logger.debug(f"Including file: {path}")
        return path.name, []
    
    children = []
    logger.debug(f"Processing children of: {path}")
    for child in sorted(path.iterdir()):
        node = node_to_tree(child, config)
        if node is not None:
            children.append(node)
    
    # Keep directories that have children or are essential
    if not children and path.name not in {'docs', 'src'}:
        logger.debug(f"Excluding empty directory: {path}")
        return None
    
    logger.debug(f"Including directory: {path} with {len(children)} children")
    return path.name, children

def generate_tree(root_dir: str = ".") -> str:
    """Generate a pretty directory tree"""
    logger.info(f"Generating tree from {root_dir}")
    
    # Load config
    project_config = load_config("pyproject.toml")
    logger.debug(f"Loaded config: {project_config}")
    
    root_path = Path(root_dir)
    logger.debug(f"Root path: {root_path.absolute()}")
    
    tree_root = node_to_tree(root_path, project_config)
    
    if tree_root is None:
        logger.warning("No tree generated - root excluded")
        return ""
    
    return format_tree(
        tree_root,
        format_node=lambda x: x[0],
        get_children=lambda x: x[1]
    )



================================================================================
File: src/readme_generator/utils.py
================================================================================
from pathlib import Path
import tomli
import os
import subprocess
from loguru import logger

def get_project_root() -> Path:
    """
    Get the project root directory by looking for pyproject.toml
    Returns the absolute path to the project root
    """
    current = Path.cwd().absolute()
    
    # Look for pyproject.toml in current and parent directories
    while current != current.parent:
        if (current / 'pyproject.toml').exists():
            return current
        current = current.parent
    
    # If we couldn't find it, use the current working directory
    # and log a warning
    logger.warning("Could not find pyproject.toml in parent directories")
    return Path.cwd().absolute()

def load_config(config_path: str) -> dict:
    """
    Load configuration from a TOML file
    
    Args:
        config_path (str): Path to the TOML configuration file relative to project root
        
    Returns:
        dict: Parsed configuration data
    """
    try:
        full_path = get_project_root() / config_path
        logger.debug(f"Attempting to load config from: {full_path}")
        with open(full_path, "rb") as f:
            return tomli.load(f)
    except FileNotFoundError:
        logger.error(f"Configuration file not found: {full_path}")
        raise

def commit_and_push(file_to_commit):
    """Commit and push changes for a specific file"""
    try:
        # Configure Git for GitHub Actions
        subprocess.run(["git", "config", "--global", "user.name", "GitHub Action"], check=True)
        subprocess.run(["git", "config", "--global", "user.email", "action@github.com"], check=True)
        
        # Check if there are any changes to commit
        status = subprocess.run(["git", "status", "--porcelain", file_to_commit], capture_output=True, text=True, check=True)
        if not status.stdout.strip():
            logger.info(f"No changes to commit for {file_to_commit}")
            return
        
        subprocess.run(["git", "add", file_to_commit], check=True)
        subprocess.run(["git", "commit", "-m", f"Update {file_to_commit}"], check=True)
        subprocess.run(["git", "push"], check=True)
        
        logger.success(f"Changes to {file_to_commit} committed and pushed successfully")
    except subprocess.CalledProcessError as e:
        logger.error(f"Error during git operations: {e}")
        if "nothing to commit" in str(e):
            logger.info("No changes to commit. Continuing execution")
        else:
            logger.warning("Exiting early due to Git error")
            raise



================================================================================
File: src/site_generator/README.md
================================================================================
# Site Generator Package

Simple static site generator for demo purposes. Currently focused on serving the project's README as a GitHub Pages site.

## Components

### Core Modules
- `generator.py`: Core site generation logic
- `__main__.py`: CLI entrypoint

## Features
- Markdown to HTML conversion
- Template-based page generation
- GitHub-style rendering
- Dark/light mode support
- Mobile-responsive design

## Usage

```bash
# Generate site with default settings
python -m site_generator build

# Specify custom output directory
python -m site_generator build --output_dir="custom_dir"
```

## Templates
Templates are stored in `docs/site/`:
- `template.html`: Base HTML template
- Additional assets (if added)

## Testing

Package-specific tests are in `tests/`:
- `test_site_generator.py`

Run tests with:
```bash
pytest tests/
```

## Customization
The site can be customized by:
- Modifying the HTML template
- Adding custom CSS/JS
- Extending the generator for additional pages



================================================================================
File: src/site_generator/__init__.py
================================================================================




================================================================================
File: src/site_generator/__main__.py
================================================================================
"""CLI entry point for site generator."""
import fire
from loguru import logger

from .generator import build_site

class SiteGenerator:
    """CLI for static site generation."""
    
    def build(self, output_dir: str = "_site") -> None:
        """
        Build the static site.
        
        Args:
            output_dir: Output directory for the site. Defaults to '_site'.
        """
        logger.info("Building static site")
        build_site(output_dir)

def main() -> None:
    """CLI entry point."""
    fire.Fire(SiteGenerator)

if __name__ == "__main__":
    main()



================================================================================
File: src/site_generator/generator.py
================================================================================
"""Core site generation functionality."""
from pathlib import Path
from typing import Optional

from loguru import logger
import markdown2

def get_project_root() -> Path:
    """Get the project root directory."""
    return Path(__file__).parent.parent.parent

def build_site(output_dir: Optional[str] = None) -> None:
    """
    Build a static site from README content.
    
    Args:
        output_dir: Optional directory for site output. Defaults to '_site'.
    """
    logger.info("Starting site generation")
    
    root = get_project_root()
    output_path = Path(output_dir or "_site")
    template_path = root / "docs" / "site" / "template.html"
    readme_path = root / "README.md"
    
    logger.debug(f"Using output directory: {output_path}")
    logger.debug(f"Using template: {template_path}")
    logger.debug(f"Using README: {readme_path}")
    
    # Validate paths
    if not template_path.exists():
        logger.error(f"Template not found: {template_path}")
        raise FileNotFoundError(f"Template not found: {template_path}")
        
    if not readme_path.exists():
        logger.error(f"README not found: {readme_path}")
        raise FileNotFoundError(f"README not found: {readme_path}")
    
    # Create output directory
    output_path.mkdir(parents=True, exist_ok=True)
    logger.debug("Created output directory")
    
    # Read template
    logger.debug("Loading template")
    with template_path.open() as f:
        template = f.read()
    
    # Convert README
    logger.info("Converting README to HTML")
    with readme_path.open() as f:
        md_content = f.read()
        html_content = markdown2.markdown(
            md_content,
            extras=['fenced-code-blocks', 'tables', 'header-ids']
        )
    
    # Generate final HTML
    logger.debug("Generating final HTML")
    final_html = template.replace('{{content}}', html_content)
    
    # Write output
    output_file = output_path / "index.html"
    logger.info(f"Writing site to: {output_file}")
    with output_file.open('w') as f:
        f.write(final_html)
    
    logger.success("Site generation complete")

if __name__ == "__main__":
    build_site()



================================================================================
File: src/summary_generator/README.md
================================================================================
# Summary Generator

Generate directory summaries to assist LLM interactions by providing focused context for each directory.

## Features

- Generates `SUMMARY` files containing concatenated content of all text files
- Skips binary files and common excludes
- Uses relative paths for file references
- Integrates with project git utilities
- Provides both API and CLI interfaces

## Usage

### Command Line

```bash
# Generate summaries for current directory
python -m summary_generator

# Generate for specific directory
python -m summary_generator /path/to/dir

# Generate without pushing changes
python -m summary_generator --push=false
```

### Python API

```python
from summary_generator import SummaryGenerator

# Create generator
generator = SummaryGenerator(".")

# Generate summaries
summary_files = generator.generate_all_summaries()
```

## Development

This package follows the project's development guidelines:

- Files are short and focused
- Uses loguru for logging
- Provides CLI through fire
- Follows consistent patterns
- Uses shared git utilities

## Testing

Tests are located in the root `tests/` directory. Run with:

```bash
pytest tests/test_summary_generator.py
```



================================================================================
File: src/summary_generator/__init__.py
================================================================================
"""Package for generating directory summaries to assist LLM interactions."""
from pathlib import Path
from typing import List

__version__ = "0.1.0"

# Re-export main functionality
from .generator import SummaryGenerator

__all__ = ["SummaryGenerator"]



================================================================================
File: src/summary_generator/__main__.py
================================================================================
import subprocess
from pathlib import Path
from typing import Optional

def commit_and_push(
    message: str,
    branch: str,
    paths: list[str | Path],
    base_branch: Optional[str] = None,
    force: bool = False
) -> None:
    """Commit changes and push to specified branch.
    
    Args:
        message: Commit message
        branch: Branch to push to
        paths: List of paths to commit
        base_branch: Optional base branch to create new branch from
        force: If True, create fresh branch and force push (for generated content)
    """
    # Convert paths to strings
    path_strs = [str(p) for p in paths]
    
    # Set up git config
    subprocess.run(["git", "config", "--local", "user.email", "github-actions[bot]@users.noreply.github.com"])
    subprocess.run(["git", "config", "--local", "user.name", "github-actions[bot]"])
    
    if force:
        # Create fresh branch from base_branch or HEAD
        base = base_branch or "HEAD"
        logger.info(f"Creating fresh branch {branch} from {base}")
        subprocess.run(["git", "checkout", "-B", branch, base])
    else:
        # Normal branch handling
        if base_branch:
            logger.info(f"Creating new branch {branch} from {base_branch}")
            subprocess.run(["git", "checkout", "-b", branch, base_branch])
        else:
            logger.info(f"Switching to branch {branch}")
            subprocess.run(["git", "checkout", "-b", branch])
            subprocess.run(["git", "pull", "origin", branch], capture_output=True)
    
    # Stage and commit changes
    subprocess.run(["git", "add", *path_strs])
    
    # Only commit if there are changes
    result = subprocess.run(
        ["git", "diff", "--staged", "--quiet"],
        capture_output=True
    )
    if result.returncode == 1:  # Changes exist
        logger.info("Committing changes")
        subprocess.run(["git", "commit", "-m", message])
        
        # Push changes
        if force:
            logger.info(f"Force pushing {branch} branch")
            subprocess.run(["git", "push", "-f", "origin", branch])
        else:
            logger.info("Pushing changes")
            subprocess.run(["git", "push", "origin", branch])
    else:
        logger.info("No changes to commit")


"""CLI entry point for summary generator."""
import fire
from loguru import logger
from pathlib import Path
from . import generator
#from readme_generator.utils import commit_and_push
from . import special_summaries


def generate(root_dir: str = ".", push: bool = True) -> list[Path]:
    """Generate directory summaries and special summaries.
    
    Args:
        root_dir: Root directory to generate summaries for
        push: Whether to commit and push changes
        
    Returns:
        List of paths to generated summary files
    """
    logger.info(f"Generating summaries for {root_dir}")
    
    # Generate regular directory summaries
    gen = generator.SummaryGenerator(root_dir)
    summary_files = gen.generate_all_summaries()
    
    # Generate special summaries
    special_files = special_summaries.generate_special_summaries(root_dir)
    all_files = summary_files + special_files
    
    if push:
        logger.info("Committing and pushing changes")
        commit_and_push(
            message="Update directory summaries and special summaries",
            branch="summaries",
            paths=all_files,
            base_branch="main",
            force=True  # Use force push for generated content
        )
    
    return all_files

def main():
    """CLI entry point."""
    fire.Fire(generate)

if __name__ == "__main__":
    main()



================================================================================
File: src/summary_generator/generator.py
================================================================================
"""Core summary generation functionality."""
from pathlib import Path
from typing import List, Set
from loguru import logger

class SummaryGenerator:
    """Generate summary files for each directory in the project."""
    
    def __init__(self, root_dir: str | Path):
        """Initialize generator with root directory.
        
        Args:
            root_dir: Root directory to generate summaries for
        """
        self.root_dir = Path(root_dir)
        
    def should_include_file(self, file_path: Path) -> bool:
        """Determine if a file should be included in the summary.
        
        Args:
            file_path: Path to file to check
            
        Returns:
            True if file should be included in summary
        """
        # Skip common files we don't want to summarize
        excluded_files = {
            '.git', '.gitignore', '.pytest_cache', '__pycache__',
            'SUMMARY', '.coverage', '.env', '.venv', '.idea', '.vscode'
        }
        
        # Skip excluded directories and files
        if any(part in excluded_files for part in file_path.parts):
            return False
            
        # Skip .github/workflows directory
        if '.github/workflows' in str(file_path):
            return False
            
        # Only include text files
        text_extensions = {'.py', '.md', '.txt', '.yml', '.yaml', '.toml', 
                         '.json', '.html', '.css', '.js', '.j2'}
        return file_path.suffix in text_extensions
    
    def should_include_directory(self, directory: Path) -> bool:
        """Determine if a directory should have a summary generated.
        
        Args:
            directory: Directory to check
            
        Returns:
            True if directory should have a summary
        """
        # Skip .github/workflows directory
        if '.github/workflows' in str(directory):
            return False
            
        # Skip other excluded directories
        excluded_dirs = {
            '.git', '__pycache__', '.pytest_cache',
            '.venv', '.idea', '.vscode'
        }
        
        return not any(part in excluded_dirs for part in directory.parts)
    
    def _collect_directories(self) -> Set[Path]:
        """Collect all directories containing files to summarize.
        
        Returns:
            Set of directory paths
        """
        directories = set()
        for file_path in self.root_dir.rglob('*'):
            if (file_path.is_file() and 
                self.should_include_file(file_path) and
                self.should_include_directory(file_path.parent)):
                directories.add(file_path.parent)
        return directories
        
    def generate_directory_summary(self, directory: Path) -> str:
        """Generate a summary for a single directory.
        
        Args:
            directory: Directory to generate summary for
            
        Returns:
            Generated summary text
        """
        logger.debug(f"Generating summary for {directory}")
        summary = []
        
        # Process all files in the directory
        for file_path in sorted(directory.rglob('*')):
            if not file_path.is_file() or not self.should_include_file(file_path):
                continue
                
            try:
                # Get relative path from root for the header
                rel_path = file_path.relative_to(self.root_dir)
                
                # Read file content
                content = file_path.read_text(encoding='utf-8')
                
                # Add to summary with clear separation
                summary.extend([
                    '=' * 80,
                    f'File: {rel_path}',
                    '=' * 80,
                    content,
                    '\n'  # Extra newline for separation
                ])
            except Exception as e:
                logger.error(f"Error processing {file_path}: {e}")
                
        return '\n'.join(summary)
        
    def generate_all_summaries(self) -> List[Path]:
        """Generate summary files for all directories.
        
        Returns:
            List of paths to generated summary files
        """
        logger.info("Starting summary generation")
        summary_files = []
        
        # Collect directories
        directories = self._collect_directories()
        logger.info(f"Found {len(directories)} directories to process")
        
        # Generate summaries
        for directory in sorted(directories):
            if not self.should_include_directory(directory):
                continue
                
            summary_content = self.generate_directory_summary(directory)
            summary_path = directory / 'SUMMARY'
            
            try:
                summary_path.write_text(summary_content, encoding='utf-8')
                logger.info(f"Generated summary for {directory}")
                summary_files.append(summary_path)
            except Exception as e:
                logger.error(f"Error writing summary for {directory}: {e}")
                
        return summary_files



================================================================================
File: src/summary_generator/signature_extractor.py
================================================================================
"""Extracts and formats Python code signatures with proper nesting."""
import ast
from dataclasses import dataclass
from pathlib import Path
from typing import List, Dict
from loguru import logger

@dataclass
class Signature:
    """Represents a Python function or class signature with documentation."""
    name: str
    kind: str  # 'function', 'method', or 'class'
    args: list[str]
    returns: str | None
    docstring: str | None
    decorators: list[str]
    methods: list['Signature']  # For storing class methods

class ParentNodeTransformer(ast.NodeTransformer):
    """Add parent references to all nodes in the AST."""
    
    def visit(self, node: ast.AST) -> ast.AST:
        """Visit a node and add parent references to all its children."""
        for child in ast.iter_child_nodes(node):
            child.parent = node
        return super().visit(node)

class SignatureExtractor:
    """Extracts detailed signatures from Python files."""
    
    def get_type_annotation(self, node: ast.AST) -> str:
        """Convert AST annotation node to string representation."""
        if isinstance(node, ast.Name):
            return node.id
        elif isinstance(node, ast.Constant):
            return repr(node.value)
        elif isinstance(node, ast.Subscript):
            container = self.get_type_annotation(node.value)
            params = self.get_type_annotation(node.slice)
            return f"{container}[{params}]"
        elif isinstance(node, ast.BinOp):
            left = self.get_type_annotation(node.left)
            right = self.get_type_annotation(node.right)
            return f"{left} | {right}"
        elif isinstance(node, ast.Tuple):
            elts = [self.get_type_annotation(e) for e in node.elts]
            return f"[{', '.join(elts)}]"
        return "Any"
    
    def get_arg_string(self, arg: ast.arg) -> str:
        """Convert function argument to string with type annotation."""
        arg_str = arg.arg
        if arg.annotation:
            type_str = self.get_type_annotation(arg.annotation)
            arg_str += f": {type_str}"
        return arg_str

    def extract_signatures(self, source: str) -> List[Signature]:
        """Extract all function and class signatures from source code."""
        try:
            # Parse and add parent references
            tree = ast.parse(source)
            transformer = ParentNodeTransformer()
            transformer.visit(tree)
            
            signatures: List[Signature] = []
            classes: Dict[ast.ClassDef, Signature] = {}
            
            for node in ast.walk(tree):
                # Handle functions
                if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                    args = []
                    for arg in node.args.args:
                        args.append(self.get_arg_string(arg))
                    
                    returns = None
                    if node.returns:
                        returns = self.get_type_annotation(node.returns)
                    
                    decorators = []
                    for decorator in node.decorator_list:
                        if isinstance(decorator, ast.Name):
                            decorators.append(f"@{decorator.id}")
                        elif isinstance(decorator, ast.Call):
                            if isinstance(decorator.func, ast.Name):
                                decorators.append(f"@{decorator.func.id}(...)")
                    
                    sig = Signature(
                        name=node.name,
                        kind='method' if hasattr(node, 'parent') and isinstance(node.parent, ast.ClassDef) else 'function',
                        args=args,
                        returns=returns,
                        docstring=ast.get_docstring(node),
                        decorators=decorators,
                        methods=[]
                    )
                    
                    # Add to appropriate parent
                    if hasattr(node, 'parent') and isinstance(node.parent, ast.ClassDef) and node.parent in classes:
                        classes[node.parent].methods.append(sig)
                    else:
                        signatures.append(sig)
                
                # Handle classes
                elif isinstance(node, ast.ClassDef):
                    bases = []
                    for base in node.bases:
                        if isinstance(base, ast.Name):
                            bases.append(base.id)
                    
                    decorators = []
                    for decorator in node.decorator_list:
                        if isinstance(decorator, ast.Name):
                            decorators.append(f"@{decorator.id}")
                    
                    class_sig = Signature(
                        name=node.name,
                        kind='class',
                        args=bases,
                        returns=None,
                        docstring=ast.get_docstring(node),
                        decorators=decorators,
                        methods=[]
                    )
                    
                    classes[node] = class_sig
                    signatures.append(class_sig)
                    
            return signatures
        except Exception as e:
            logger.error(f"Error parsing source: {e}")
            return []

    def format_signature(self, sig: Signature, indent: int = 0) -> List[str]:
        """Format a signature for display with proper indentation."""
        lines = []
        indent_str = "    " * indent
        
        # Add decorators
        for decorator in sig.decorators:
            lines.append(f"{indent_str}{decorator}")
        
        # Format the signature line
        if sig.kind == 'class':
            base_str = f"({', '.join(sig.args)})" if sig.args else ""
            lines.append(f"{indent_str}class {sig.name}{base_str}")
        else:
            async_prefix = "async " if "async" in sig.decorators else ""
            args_str = ", ".join(sig.args)
            return_str = f" -> {sig.returns}" if sig.returns else ""
            lines.append(f"{indent_str}{async_prefix}def {sig.name}({args_str}){return_str}")
        
        # Add docstring if present
        if sig.docstring:
            doc_lines = sig.docstring.split('\n')
            if len(doc_lines) == 1:
                lines.append(f'{indent_str}    """{sig.docstring}"""')
            else:
                lines.append(f'{indent_str}    """')
                for doc_line in doc_lines:
                    if doc_line.strip():
                        lines.append(f"{indent_str}    {doc_line}")
                lines.append(f'{indent_str}    """')
        
        # Add methods for classes
        if sig.methods:
            lines.append("")  # Add spacing
            for method in sig.methods:
                lines.extend(self.format_signature(method, indent + 1))
                lines.append("")  # Add spacing between methods
        
        return lines

def generate_python_summary(root_dir: str | Path) -> str:
    """Generate enhanced Python project structure summary.
    
    Args:
        root_dir: Root directory of the project
        
    Returns:
        Formatted markdown string of Python signatures
    """
    root_dir = Path(root_dir)
    extractor = SignatureExtractor()
    content = ["# Python Project Structure\n"]
    
    for file in sorted(root_dir.rglob("*.py")):
        if any(part.startswith('.') for part in file.parts):
            continue
        if '__pycache__' in file.parts:
            continue
            
        try:
            # Get relative path
            rel_path = file.relative_to(root_dir)
            
            # Read and extract signatures
            source = file.read_text()
            signatures = extractor.extract_signatures(source)
            
            # Only include files that have actual content
            if signatures:
                content.append(f"## {rel_path}")
                content.append("```python")
                
                # Format each signature
                for sig in signatures:
                    content.extend(extractor.format_signature(sig))
                    content.append("")  # Add spacing between top-level items
                
                content.append("```\n")
            
        except Exception as e:
            logger.error(f"Error processing {file}: {e}")
    
    return "\n".join(content)



================================================================================
File: src/summary_generator/special_summaries.py
================================================================================
"""Special summary generators for project-wide summaries."""
from pathlib import Path
from typing import List
from loguru import logger
from .signature_extractor import SignatureExtractor, generate_python_summary  # New import

class SpecialSummariesGenerator:
    """Generate special project-wide summary files."""
    
    def __init__(self, root_dir: str | Path):
        """Initialize generator with root directory."""
        self.root_dir = Path(root_dir)
        self.summaries_dir = self.root_dir / "SUMMARIES"
        self.signature_extractor = SignatureExtractor()  # New instance
    
    def _find_readmes(self, include_root: bool = True) -> List[Path]:
        """Find all README files in the project."""
        readmes = []
        for file in self.root_dir.rglob("README.md"):
            if not include_root and file.parent == self.root_dir:
                continue
            readmes.append(file)
        return sorted(readmes)
    
    def generate_special_summaries(self) -> List[Path]:
        """Generate all special summary files.
        
        Returns:
            List of paths to generated summary files
        """
        self.summaries_dir.mkdir(exist_ok=True)
        generated_files = []
        
        # Generate READMEs.md
        readmes_path = self.summaries_dir / "READMEs.md"
        readme_content = []
        for readme in self._find_readmes(include_root=True):
            rel_path = readme.relative_to(self.root_dir)
            readme_content.extend([
                "=" * 80,
                f"# {rel_path}",
                "=" * 80,
                readme.read_text(),
                "\n"
            ])
        readmes_path.write_text("\n".join(readme_content))
        generated_files.append(readmes_path)
        
        # Generate README_SUBs.md
        subs_path = self.summaries_dir / "README_SUBs.md"
        subs_content = []
        for readme in self._find_readmes(include_root=False):
            rel_path = readme.relative_to(self.root_dir)
            subs_content.extend([
                "=" * 80,
                f"# {rel_path}",
                "=" * 80,
                readme.read_text(),
                "\n"
            ])
        subs_path.write_text("\n".join(subs_content))
        generated_files.append(subs_path)
        
        # Generate enhanced PYTHON.md
        python_path = self.summaries_dir / "PYTHON.md"
        python_content = generate_python_summary(self.root_dir)  # Using new generator
        python_path.write_text(python_content)
        generated_files.append(python_path)
        
        return generated_files

def generate_special_summaries(root_dir: str | Path = ".") -> List[Path]:
    """Generate special summaries for the project."""
    generator = SpecialSummariesGenerator(root_dir)
    return generator.generate_special_summaries()



================================================================================
File: tests/conftest.py
================================================================================
import pytest
from pathlib import Path
import tempfile
import shutil

@pytest.fixture
def temp_dir():
    """Provide a clean temporary directory"""
    with tempfile.TemporaryDirectory() as td:
        yield Path(td)

@pytest.fixture
def mock_repo(temp_dir):
    """Create a mock repository structure for testing"""
    # Create basic structure
    docs_dir = temp_dir / "docs" / "readme" / "sections"
    src_dir = temp_dir / "src" / "readme_generator"
    
    docs_dir.mkdir(parents=True)
    src_dir.mkdir(parents=True)
    
    # Create mock files
    (docs_dir / "introduction.md.j2").write_text("## Introduction\n{{ test }}")
    (temp_dir / "pyproject.toml").write_text("""
[project]
name = "test-project"
version = "0.1.0"

[tool.readme]
test = "Test Value"
    """)
    
    return temp_dir



================================================================================
File: tests/test_generators.py
================================================================================
from pathlib import Path
import pytest
from readme_generator.generators.tree_generator import generate_tree
from readme_generator.generators.readme_generator import generate_readme
from readme_generator.utils import get_project_root, load_config

def test_tree_generator(mock_repo):
    """Test tree generation with mock repository"""
    tree = generate_tree(str(mock_repo))
    assert "docs" in tree
    assert "src" in tree
    assert "pyproject.toml" in tree

def test_load_config(mock_repo):
    """Test configuration loading"""
    config = load_config(str(mock_repo / "pyproject.toml"))
    assert config["project"]["name"] == "test-project"
    assert config["project"]["version"] == "0.1.0"

def test_project_root(mock_repo, monkeypatch):
    """Test project root detection"""
    monkeypatch.chdir(mock_repo)
    root = get_project_root()
    assert root.samefile(mock_repo)



================================================================================
File: tests/test_site_generator.py
================================================================================
"""Tests for site generation functionality."""
import pytest
from pathlib import Path

from site_generator.generator import build_site

@pytest.fixture
def temp_site_dir(tmp_path):
    """Provide a temporary directory for site output."""
    return tmp_path / "site"

@pytest.fixture
def mock_readme(tmp_path):
    """Create a mock README file."""
    readme = tmp_path / "README.md"
    readme.write_text("# Test\nThis is a test README.")
    return readme

@pytest.fixture
def mock_template(tmp_path):
    """Create a mock template file."""
    template_dir = tmp_path / "docs" / "site"
    template_dir.mkdir(parents=True)
    template = template_dir / "template.html"
    template.write_text("<html><body>{{content}}</body></html>")
    return template

def test_build_site(temp_site_dir, mock_readme, mock_template, monkeypatch):
    """Test basic site generation."""
    # Mock get_project_root to use our temp directory
    monkeypatch.setattr(
        "site_generator.generator.get_project_root",
        lambda: mock_readme.parent
    )
    
    # Build site
    build_site(str(temp_site_dir))
    
    # Verify output
    assert temp_site_dir.exists()
    assert (temp_site_dir / "index.html").exists()
    
    # Check content
    content = (temp_site_dir / "index.html").read_text()
    assert '<h1 id="test">Test</h1>' in content
    assert "This is a test README." in content

def test_build_site_missing_template(temp_site_dir, mock_readme, monkeypatch):
    """Test handling of missing template."""
    # Mock get_project_root to use our temp directory
    monkeypatch.setattr(
        "site_generator.generator.get_project_root",
        lambda: mock_readme.parent
    )
    
    with pytest.raises(FileNotFoundError, match="Template not found"):
        build_site(str(temp_site_dir))

def test_build_site_missing_readme(temp_site_dir, mock_template, monkeypatch):
    """Test handling of missing README."""
    # Mock get_project_root to use template directory parent
    monkeypatch.setattr(
        "site_generator.generator.get_project_root",
        lambda: mock_template.parent.parent.parent
    )
    
    with pytest.raises(FileNotFoundError, match="README not found"):
        build_site(str(temp_site_dir))



================================================================================
File: tests/test_summary_generator.py
================================================================================
"""Tests for summary generator package."""
import pytest
from pathlib import Path
from summary_generator import SummaryGenerator

@pytest.fixture
def temp_project(tmp_path):
    """Create a temporary project structure."""
    # Create some test files
    (tmp_path / "README.md").write_text("# Test Project")
    (tmp_path / "src").mkdir()
    (tmp_path / "src/main.py").write_text("print('hello')")
    (tmp_path / "src/utils.py").write_text("def test(): pass")
    (tmp_path / ".git").mkdir()
    (tmp_path / ".git/config").write_text("git config")
    return tmp_path

@pytest.fixture
def generator(temp_project):
    """Create a summary generator instance."""
    return SummaryGenerator(temp_project)

def test_should_include_file(generator):
    """Test file inclusion logic."""
    # Should include normal text files
    assert generator.should_include_file(Path("test.py"))
    assert generator.should_include_file(Path("test.md"))
    assert generator.should_include_file(Path("test.yml"))
    
    # Should exclude special files
    assert not generator.should_include_file(Path(".git/config"))
    assert not generator.should_include_file(Path("__pycache__/test.pyc"))
    assert not generator.should_include_file(Path("SUMMARY"))
    
    # Should exclude binary files
    assert not generator.should_include_file(Path("test.png"))
    assert not generator.should_include_file(Path("test.pyc"))

def test_generate_directory_summary(generator, temp_project):
    """Test summary generation for a directory."""
    summary = generator.generate_directory_summary(temp_project / "src")
    
    # Should include both Python files
    assert "main.py" in summary
    assert "utils.py" in summary
    assert "print('hello')" in summary
    assert "def test(): pass" in summary
    
    # Should have proper separators
    assert "=" * 80 in summary
    assert "File:" in summary

def test_generate_all_summaries(generator, temp_project):
    """Test generating summaries for all directories."""
    summary_files = generator.generate_all_summaries()
    
    # Should generate summaries in correct locations
    assert len(summary_files) == 2  # Root and src directories
    assert (temp_project / "SUMMARY") in summary_files
    assert (temp_project / "src/SUMMARY") in summary_files
    
    # Summaries should contain correct content
    root_summary = (temp_project / "SUMMARY").read_text()
    assert "# Test Project" in root_summary
    
    src_summary = (temp_project / "src/SUMMARY").read_text()
    assert "print('hello')" in src_summary
    assert "def test(): pass" in src_summary



================================================================================
File: tests/test_tree_generator.py
================================================================================
from loguru import logger
from pathlib import Path
import pytest
from readme_generator.generators.tree_generator import (
    should_include_path,
    node_to_tree,
    generate_tree
)

@pytest.fixture
def mock_repo_with_files(mock_repo):
    """Create a mock repository with various file types"""
    # Add workflow files
    workflow_dir = mock_repo / ".github" / "workflows"
    workflow_dir.mkdir(parents=True)
    (workflow_dir / "test.yml").write_text("name: Test")
    (workflow_dir / "build.yml").write_text("name: Build")
    
    # Add various hidden files
    (mock_repo / ".env").write_text("SECRET=123")
    (mock_repo / ".github" / "README.md").write_text("# GitHub Config")
    
    # Add some regular files and directories
    docs_dir = mock_repo / "docs" / "readme" / "sections"
    docs_dir.mkdir(parents=True, exist_ok=True)  # Added exist_ok=True
    (docs_dir / "introduction.md").write_text("# Intro")
    
    # Add some files that should typically be ignored
    cache_dir = mock_repo / "__pycache__"
    cache_dir.mkdir(exist_ok=True)  # Added exist_ok=True
    (cache_dir / "module.pyc").write_text("cache")
    
    return mock_repo

def test_ignore_patterns():
    """Test that ignore patterns work correctly"""
    config = {
        "tool": {
            "readme": {
                "tree": {
                    "ignore_patterns": [".git", "__pycache__", "*.pyc"]
                }
            }
        }
    }
    
    # Should exclude based on exact pattern matches
    assert should_include_path(Path(".git/config"), config) is False
    assert should_include_path(Path("foo/__pycache__/bar.pyc"), config) is False
    assert should_include_path(Path("test.pyc"), config) is False
    
    # Should include non-matching paths
    assert should_include_path(Path(".github/workflows/test.yml"), config) is True  # .github != .git
    assert should_include_path(Path(".env"), config) is True
    assert should_include_path(Path("docs/readme/file.md"), config) is True
    assert should_include_path(Path(".vscode/settings.json"), config) is True
    assert should_include_path(Path("my_cache/file.txt"), config) is True  # Only exact __pycache__ matches

def test_full_tree_generation(mock_repo_with_files, monkeypatch):
    """Test complete tree generation with various file types"""
    monkeypatch.chdir(mock_repo_with_files)
    
    # Create config that only ignores specific patterns
    (mock_repo_with_files / "pyproject.toml").write_text("""
[tool.readme.tree]
ignore_patterns = ["__pycache__", "*.pyc", ".git"]
    """)
    
    tree = generate_tree(".")
    print(f"Generated tree:\n{tree}")  # Debug output
    
    # Should include .github and workflows
    assert ".github" in tree
    assert "workflows" in tree
    assert "test.yml" in tree
    assert "build.yml" in tree
    
    # Should include other hidden files not explicitly ignored
    assert ".env" in tree
    
    # Should include regular files and directories
    assert "docs" in tree
    assert "readme" in tree
    assert "sections" in tree
    
    # Should exclude ignored patterns
    assert "__pycache__" not in tree
    assert "*.pyc" not in tree

def test_empty_directory_handling(mock_repo):
    """Test handling of empty directories"""
    # Create some empty directories
    (mock_repo / "docs" / "empty").mkdir(parents=True, exist_ok=True)
    (mock_repo / "src" / "empty").mkdir(parents=True, exist_ok=True)
    (mock_repo / "temp" / "empty").mkdir(parents=True, exist_ok=True)
    
    config = {
        "tool": {
            "readme": {
                "tree": {
                    "ignore_patterns": []
                }
            }
        }
    }
    
    # Empty directories should be excluded unless they're essential
    assert node_to_tree(mock_repo / "temp" / "empty", config) is None
    
    # Essential directories should be kept even if empty
    assert node_to_tree(mock_repo / "docs", config) is not None
    assert node_to_tree(mock_repo / "src", config) is not None

def test_debug_path_processing(mock_repo_with_files):
    """Debug test to print path processing details"""
    config = {
        "tool": {
            "readme": {
                "tree": {
                    "ignore_patterns": ["__pycache__", "*.pyc"]
                }
            }
        }
    }
    
    def debug_walk(path: Path, indent=""):
        logger.debug(f"{indent}Processing: {path}")
        logger.debug(f"{indent}Should include: {should_include_path(path, config)}")
        
        if path.is_dir():
            for child in sorted(path.iterdir()):
                debug_walk(child, indent + "  ")
    
    logger.debug("Starting debug walk of repository")
    debug_walk(mock_repo_with_files)


